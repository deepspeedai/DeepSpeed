################################################################################
# DeepSpeed CI - AWS L40S GPU Tests (PyTorch Latest)
#
# Runs the same tests as modal-torch-latest.yml but on AWS self-hosted runners.
# Uses 4x NVIDIA L40S GPUs on g6e.12xlarge instances.
################################################################################

name: aws-torch-latest

on:
  workflow_dispatch:

  push:
    branches:
      - master

  pull_request:
    branches:
      - master

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  check-paths:
    name: Check Paths
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.filter.outputs.run_tests }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            run_tests:
              - '**'
              - '!docs/**'
              - '!blogs/**'
              - '!deepspeed/inference/v2/**'
              - '!tests/unit/inference/v2/**'

  unit-tests:
    name: Unit Tests (Full)
    needs: check-paths
    if: needs.check-paths.outputs.should_run == 'true'
    runs-on: [self-hosted, gpu-ci, gpu-l40s, l40s-4gpu, aws]
    timeout-minutes: 180

    container:
      image: nvidia/cuda:12.6.3-devel-ubuntu22.04
      # Mount /mnt/aio for async I/O tests (O_DIRECT requires native filesystem, not overlayfs)
      options: --gpus all --shm-size "32G" -v /mnt/aio:/mnt/aio

    env:
      TORCH_VER: "2.7"
      CUDA_VER: "12.6"
      # Disable reuse_dist_env to prevent pool worker cleanup hangs in full test runs
      DS_DISABLE_REUSE_DIST_ENV: "1"

    steps:
      - name: Install system dependencies
        run: |
          apt-get update && apt-get install -y git git-lfs libaio-dev pdsh python3 python3-pip
          git lfs install
          ln -sf /usr/bin/python3 /usr/bin/python

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Install PyTorch
        run: |
          pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu126

      - name: Install transformers
        run: |
          git clone https://github.com/huggingface/transformers
          cd transformers
          git checkout 981c276
          pip install .

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements/requirements.txt
          pip install -r requirements/requirements-dev.txt
          pip install -r requirements/requirements-deepcompile.txt
          pip install pytest-timeout pytest-instafail

      - name: Check environment
        run: |
          echo "=== GPU Information ==="
          nvidia-smi
          echo ""
          echo "=== CUDA Version ==="
          nvcc --version
          echo ""
          echo "=== Python/PyTorch Info ==="
          python --version
          python -c "import torch; print(f'PyTorch: {torch.__version__}')"
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          python -c "import torch; print(f'CUDA devices: {torch.cuda.device_count()}')"
          python -c "import torch; print(f'BF16 support: {torch.cuda.is_bf16_supported()}')"

      - name: Install DeepSpeed
        run: |
          # Initialize CUDA before install so setup.py can detect NCCL version
          python -c "import torch; torch.cuda.init(); print(f'NCCL version: {torch.cuda.nccl.version()}')"
          # Use --no-build-isolation so setup.py can access pre-installed PyTorch
          pip install --no-build-isolation .[dev,1bit,autotuning,deepcompile]
          ds_report
          # Debug: Check captured torch_info values
          python -c "from deepspeed.git_version_info import torch_info; print(f'torch_info: {torch_info}')"

      - name: Python environment
        run: |
          pip list

      - name: Debug testRowParallel (5 seeds)
        run: |
          export TORCH_CUDA_ARCH_LIST="8.9"
          cd tests
          echo "=== Running testRowParallel with 5 different seeds ==="
          for seed in 12345 54321 99999 11111 77777; do
            echo ""
            echo "=========================================="
            echo "SEED: $seed"
            echo "=========================================="
            rm -rf /mnt/aio/pytest
            PYTHONHASHSEED=$seed pytest -v --forked --basetemp=/mnt/aio/pytest \
              unit/model_parallelism/test_autotp_training.py::TestTpLayerFwdBwd::testRowParallel \
              --torch_ver=${{ env.TORCH_VER }} --cuda_ver=${{ env.CUDA_VER }} \
              || echo "FAILED with seed $seed"
          done

      - name: Sequential tests run 1 (seed 12345)
        run: |
          export TORCH_CUDA_ARCH_LIST="8.9"
          cd tests
          echo "=== Sequential tests - seed 12345 ==="
          rm -rf /mnt/aio/pytest
          PYTHONHASHSEED=12345 pytest --instafail --timeout 600 --forked -m 'sequential' --basetemp=/mnt/aio/pytest unit/ \
            --ignore=unit/runtime/zero/test_nvme_checkpointing.py \
            --ignore=unit/ops/aio/test_gds.py \
            --ignore=unit/launcher/test_user_args.py \
            --ignore=unit/runtime/zenflow \
            --ignore=unit/ops/adam/test_zf_torch_adam.py \
            --torch_ver=${{ env.TORCH_VER }} --cuda_ver=${{ env.CUDA_VER }}

      - name: Sequential tests run 2 (seed 54321)
        run: |
          export TORCH_CUDA_ARCH_LIST="8.9"
          cd tests
          echo "=== Sequential tests - seed 54321 ==="
          rm -rf /mnt/aio/pytest
          PYTHONHASHSEED=54321 pytest --instafail --timeout 600 --forked -m 'sequential' --basetemp=/mnt/aio/pytest unit/ \
            --ignore=unit/runtime/zero/test_nvme_checkpointing.py \
            --ignore=unit/ops/aio/test_gds.py \
            --ignore=unit/launcher/test_user_args.py \
            --ignore=unit/runtime/zenflow \
            --ignore=unit/ops/adam/test_zf_torch_adam.py \
            --torch_ver=${{ env.TORCH_VER }} --cuda_ver=${{ env.CUDA_VER }}

      - name: Sequential tests run 3 (seed 99999)
        run: |
          export TORCH_CUDA_ARCH_LIST="8.9"
          cd tests
          echo "=== Sequential tests - seed 99999 ==="
          rm -rf /mnt/aio/pytest
          PYTHONHASHSEED=99999 pytest --instafail --timeout 600 --forked -m 'sequential' --basetemp=/mnt/aio/pytest unit/ \
            --ignore=unit/runtime/zero/test_nvme_checkpointing.py \
            --ignore=unit/ops/aio/test_gds.py \
            --ignore=unit/launcher/test_user_args.py \
            --ignore=unit/runtime/zenflow \
            --ignore=unit/ops/adam/test_zf_torch_adam.py \
            --torch_ver=${{ env.TORCH_VER }} --cuda_ver=${{ env.CUDA_VER }}
