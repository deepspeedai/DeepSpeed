name: nv-lightning-v100

on:
  push:
    branches:
      - 'master'
      - 'staging**'
    paths-ignore:
      - 'docs/**'
  pull_request:
    paths-ignore:
      - 'docs/**'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, cu111, v100]

    steps:
      - uses: actions/checkout@v2

      - name: environment
        run: |
          echo "JobID: $AISC_NODE_INSTANCE_ID"
          nvidia-smi
          which python
          python --version
          which nvcc
          nvcc --version
          pip install --upgrade pip
          pip uninstall --yes torch torchvision
          pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html
          # Since the cupy install that happens in DS's setup.py gets the cuda
          # version from pytorch/driver api (and not nvcc/runtime api), it's
          # possible that when torch releases a new version, the DS install
          # will install a new version of cupy. The resulting environment
          # causes an error when import cupy. To avoid this, we uninstall cupy.
          pip uninstall --yes $(pip list | grep -Po "cupy[^\s]*" | tr '\n' ' ')
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Python environment
        run: |
          pip list

      - name: Install deepspeed
        run: |
          pip uninstall --yes deepspeed
          pip install .[dev,autotuning]
          ds_report

      - name: PyTorch Lightning Tests
        run: |
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          pip uninstall --yes pytorch-lightning
          pip install pytorch-lightning
          pip install "protobuf<4.21.0"
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions pytest --color=yes --durations=0 --verbose lightning/
